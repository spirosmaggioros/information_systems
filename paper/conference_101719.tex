\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{amsmath}
\usepackage{bm}
\usepackage{booktabs}
\usepackage{unicode-math}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\makeatletter
\newcommand{\linebreakand}{%
  \end{@IEEEauthorhalign}
  \hfill\mbox{}\par
  \mbox{}\hfill\begin{@IEEEauthorhalign}
}
\makeatother

\begin{document}

\title{An analyses of GNN and graph representational models on real-world datasets}

\author{
\IEEEauthorblockN{Spiros Maggioros\IEEEauthorrefmark{1}\IEEEauthorrefmark{2}}
\IEEEauthorblockA{
Spiros.Maggioros@pennmedicine.upenn.edu
}
\and
\IEEEauthorblockN{Reinti Pasai\IEEEauthorrefmark{1}}
\IEEEauthorblockA{
reidipasai03@gmail.com
}
\linebreakand
\IEEEauthorblockN{Eleni Nasopoulou\IEEEauthorrefmark{1}}
\IEEEauthorblockA{
el21087@mail.ntua.gr
}
\\
\IEEEauthorblockA{
\IEEEauthorrefmark{1}National Technical University of Athens, Athens, Greece \\
\IEEEauthorrefmark{2}AI$^2$D Center, University of Pennsylvania, Philadelphia, PA, USA
}
}

\maketitle

\begin{abstract}

\end{abstract}

\begin{IEEEkeywords}
Graphs, Graph Neural Networks, Kernels, Deep Learning, Representation Learning
\end{IEEEkeywords}

\section{Introduction}

Graph-structured data appear across diverse domains from molecular chemistry and protein networks to social media and cybersecurity systems. The fundamental challenge lies in transforming graph structures into fixed-dimensional vectors amenable to machine learning algorithms. Graph embedding methods address this by mapping graphs into continuous vector spaces that preserve structural and semantic properties while enabling efficient computation. Traditional graph analysis relies on graph kernels that use handcrafted features such as shortest paths, graphlets, and random walks \cite{shervashidze2011weisfeiler}. While theoretically sound, these approaches suffer from poor generalization across domains, require domain expertise for feature engineering, and fail to capture complex patterns in large-scale networks. Moreover, kernel methods typically lack explicit embeddings, restricting compatibility with general-purpose learning algorithms. Recent advances in deep learning have enabled a shift toward data-driven graph embeddings. Inspired by natural language processing techniques that learn distributed representations of words and documents \cite{mikolov2013efficientestimationwordrepresentations, mikolov2013distributedrepresentationswordsphrases}, \textbf{(change modern)} modern approaches treat graphs as documents and subgraphs as words. This paradigm encompasses unsupervised methods like Graph2Vec \cite{narayanan2017graph2veclearningdistributedrepresentations} and DeepWalk \cite{Perozzi_2014} that learn task-agnostic representations.

Graph2Vec, DeepWalk, and NetLSD \cite{Tsitsulin_2018} are unsupervised methods that learn exclusively from graph topology without node features or labels. This structural focus enables rapid training and high computational efficiency, making them suitable for large-scale applications where labeled data is unavailable. However, ignoring node attributes typically yields lower classification accuracy than supervised methods. These embeddings often serve as auxiliary features for node-level prediction or initialization for supervised models. This work evaluates these trade-offs through empirical benchmarking across classification, clustering, efficiency, and robustness. 

First introduced by Micheli, 2009 \cite{MicheliGNN} and Scarselli et al., 2008 \cite{scarselliGNN} as a form of recurrent neural network \cite{kipf2017semisupervisedclassificationgraphconvolutional}, Graph Neural Networks (GNNs) have recently become a widely used method to tackle problems like classification and link prediction tasks in domains like social networks, telecommunication networks, biological networks or brain connectomes \cite{veličković2018graphattentionnetworks} where other learning techniques fail. Almost all modern message-passing GNN models use convolutional or attentional layers and an aggregation process to compute latent embeddings. Thus, GNNs excel when applied to networks where nodes include features, in contrast with graph representation learning models that only capture the network structure. Despite their current appeal, GNNs are criticized by many for their limited expressiveness and generalization. Xu et al. \cite{xu2019powerfulgraphneuralnetworks} proved that GNNs are as powerful as the 1-WL algorithm and highlighted the minimal discriminative power of commonly used aggregators. Currently, GNN models occupy top positions on the Open Graph Benchmark (OGB) \cite{opengraphbenchmarkdatasets} and Long-Range Graph Benchmark (LRGB) \cite{dwivedi2023longrangegraphbenchmark} leaderboards. Nevertheless, classic GNNs still lead the leaderboard in some of these benchmarks \cite{luo2025classicgnnsstrongbaselines}. In this work, we are going to evaluate a number of these models on social, bio-informatics and small molecules networks evaluating classification performance, clustering quality, computational efficiency, and robustness to perturbations. Our contributions include comprehensive empirical comparison under controlled conditions, investigation of embedding dimensionality trade-offs, and assessment of robustness characteristics for real-world deployment.

\section{Related Work}

\subsection{Graph2Vec}

Graph2Vec \cite{narayanan2017graph2veclearningdistributedrepresentations} addresses fundamental limitations of node level embedding aggregation by extending document embedding approaches, particularly doc2vec \cite{le2014distributedrepresentationssentencesdocuments, mikolov2013efficientestimationwordrepresentations}, to whole-graph representation learning. The method treats entire graphs as documents and rooted subgraphs extracted through Weisfeiler Lehman relabeling \cite{shervashidze2011weisfeiler} as vocabulary words, enabling unsupervised embedding via skip-gram training \cite{mikolov2013efficientestimationwordrepresentations}. This approach represents a significant departure from traditional graph kernels that rely on handcrafted structural features, instead learning data-driven representations adapted to specific graph corpora. On benchmark graph classification datasets, Graph2Vec achieves $83.15\%$ accuracy on MUTAG, $60.17\%$ on PTC, and $73.30\%$ on PROTEINS, substantially outperforming node-level aggregation approaches by over 10 percentage points \cite{narayanan2017graph2veclearningdistributedrepresentations}. The method demonstrates particular strength on large-scale datasets where data-driven learning shows clear advantages. On Android malware detection involving 10,560 API dependency graphs with average size of 2,637 nodes, Graph2Vec achieves $99.03\%$ accuracy, surpassing Deep WL kernels ($98.16\%$) \cite{yanardag2015deepgraphkernels}, WL kernels ($97.12\%$) \cite{shervashidze2011weisfeiler}, and substantially outperforming node2vec ($81.25\%$) and sub2vec ($76.83\%$) \cite{narayanan2017graph2veclearningdistributedrepresentations, adhikari2017distributedrepresentationsubgraphs}. This 18 percentage point improvement over node2vec aggregation suggests that global structural properties cannot be adequately recovered through local node representations alone.

However, Graph2Vec exhibits mixed performance across different dataset characteristics. On NCI1 and NCI109 molecular datasets, it achieves $73.22\%$ and $74.26\%$ accuracy respectively, compared to approximately $80\%$ for WL kernels \cite{shervashidze2011weisfeiler}. This performance gap suggests that Graph2Vec’s data-driven approach requires sufficient training examples to surpass carefully designed handcrafted features, particularly on smaller datasets with limited structural diversity. Computational efficiency analysis reveals Graph2Vec occupies a middle ground: slower than node2vec due to subgraph extraction overhead, yet significantly faster than sub2vec which requires extensive random walk sampling. The method generalizes well to unseen graphs when trained on large, diverse datasets but struggles with limited training data or low structural variation.

\subsection{DeepWalk}

DeepWalk \cite{Perozzi_2014} pioneered the application of neural language modeling to network representation learning by establishing a formal connection between graph topology and natural language structure. The method treats truncated random walks on graphs as sentences in a corpus, recognizing that vertex sequences exhibit power-law frequency distributions similar to word distributions in natural language. This insight enables direct application of skip-gram models \cite{mikolov2013efficientestimationwordrepresentations} to learn vertex embeddings that capture neighborhood relationships and community structure.

Originally designed for node-level tasks, DeepWalk demonstrates substantial improvements over spectral clustering methods on social network datasets. DeepWalk achieves up to 10\% higher F1-scores on social networks such as BlogCatalog, Flickr, and YouTube, and in some configurations (e.g., on Flickr) it matches or surpasses baselines while using 60\% less labeled training data \cite{Perozzi_2014}. DeepWalk's online learning algorithm and trivial parallelization enable exceptional scalability, processing networks with millions of nodes efficiently. This scalability makes DeepWalk applicable to web-scale graphs where batch spectral methods become computationally prohibitive.

DeepWalk established the foundation for subsequent node embedding methods, most notably node2vec \cite{grover2016node2vecscalablefeaturelearning}, which extends DeepWalk with biased random walk strategies controlled by return parameter $p$ and in-out parameter $q$. Node2vec achieves 22.3\% relative improvement over DeepWalk in Macro-F1 scores on BlogCatalog and 21.8\% on Wikipedia by learning appropriate exploration strategies that balance breadth-first and depth-first search \cite{grover2016node2vecscalablefeaturelearning}. For link prediction tasks, node2vec outperforms DeepWalk by up to 3.8\% in AUC scores across multiple network types. However, DeepWalk's uniform random walk strategy provides limited control over neighborhood exploration, potentially missing important structural patterns that biased strategies can capture.

A critical limitation emerges when applying DeepWalk to whole-graph tasks. Since DeepWalk produces node-level embeddings, adapting it for graph-level representation requires aggregation strategies such as averaging or pooling. Simply averaging DeepWalk or node2vec embeddings yields only 81.25\% accuracy on Android malware detection \cite{narayanan2017graph2veclearningdistributedrepresentations}, an 18 percentage point gap compared to methods designed explicitly for graph-level representation. This substantial performance difference demonstrates that global structural properties are not adequately captured through local node aggregation, motivating the development of whole-graph embedding approaches like Graph2Vec that directly learn graph-level representations.

\subsection{Graph Neural Networks}
Due to deep learning being a defacto standard for various tasks, a lot of effort has been put to generalize neural networks to graph structured data. A pioneer modern work was proposed by Kipf and Welling \cite{kipf2017semisupervisedclassificationgraphconvolutional}, GCNs are still used to this day due to their scalability. Another big step was made by veličković et al. with Graph Attentional Networks(GAT) \cite{veličković2018graphattentionnetworks} that leveraged masked self-attentional layers enabling nodes to attend over their neighborhood's features. This was later improved by Brody et al. \cite{brody2022attentivegraphattentionnetworks} proposing GATv2, improving the average error by $11.5\%$ in some tasks. In 2019, Xu et al. \cite{xu2019powerfulgraphneuralnetworks} proposed Graph Isomorphism Networks(GIN), proving that GNNs are at most as powerful as the 1-WL test and identifying graph structures that aforementioned GNNs can't distinguish. Corso et al. \cite{corso2020principalneighbourhoodaggregationgraph}, taking advantage of the analysis presented at \cite{xu2019powerfulgraphneuralnetworks}, introduced Principal Neighborhood Aggregation(PNA), a architecture that combines multiple aggregators with degree-scalers, proving that using a single aggregator fails to distinguish simple graph structures. All Aforementioned GNNs make up the "classic" models, modern GNN models leverage SSL \cite{chien2022nodefeatureextractionselfsupervised}, \cite{veličković2018deepgraphinfomax}, which is particularly useful in graph datasets where we might have text or images as input and labels are not always known. The GIANT framework proposed at \cite{chien2022nodefeatureextractionselfsupervised} uses XR-Transformers, a model that is considered state-of-the-art, the resulting transformer is then used as ans encoder to generate numerical node features for each node, the encoder can change to address other data forms like images, where a CNN can be used. Though the GIANT framework dominates node property prediction leaderboards, it's not widely used for graph-level tasks, and interestingly so, work proposed by \cite{luo2025classicgnnsstrongbaselines} showed that classic GNN models can still produce strong results at graph-level tasks when used with edge features, normalization, dropout, residual connections, feed-forward networks and positional encoding.

\subsection{NetLSD}
To address the ubiquitous yet computationally challenging task of graph comparison, Tsitsulin et al. \cite{Tsitsulin_2018} introduced the Network Laplacian Spectral Descriptor (NetLSD). While ideal comparison measures must be permutation-invariant, size-invariant, and scale-adaptive, prior methods have struggled to satisfy these desiderata simultaneously. For instance, Graph Edit Distance (GED) \cite{RIESEN2009950} is NP-hard \cite{10.5555/646337.688400} and computationally prohibitive for large collections, while alternative graph kernels \cite{10.1109/ICDM.2005.132, 10.1007/978-3-540-45167-9_11, kondor2016multiscalelaplaciangraphkernel, Nikolentzos_Meladianos_Vazirgiannis_2017, JMLR:v12:shervashidze11a, 10.1145/2783258.2783417} and statistical representations like FGSD \cite{NIPS2017_d2ddea18} often lack scalability. Grounded in spectral graph theory and drawing on the physical analogy by Kac \cite{6d1fe8e1-9a0d-30f4-aeb4-baa6cceccb15} regarding whether one can "hear the shape" of an object, NetLSD extracts a compact, continuous graph signature derived from the solution of the heat \cite{5661779, 10.5555/1735603.1735621} or wave \cite{6130444} kernel involving the normalized Laplacian matrix. This approach ensures the method is not only expressive, inheriting the formal properties of the Laplacian spectrum commonly utilized in graph mining \cite{10.1007/978-3-642-13672-6_40, 868688}, but also computationally efficient, enabling constant-time similarity computations that outperform previous works in both expressiveness and efficiency.

NetLSD \cite{Tsitsulin_2018} demonstrates scalability and robustness across diverse graph analysis tasks, consistently outperforming representation-based baselines such as NetSimile \cite{10.1145/2492517.2492582} and FGSD \cite{NIPS2017_d2ddea18}. The method proves particularly effective in distinguishing global structural patterns, such as community organization within Stochastic Block Models (SBM). In scenarios where graph size increases, NetLSD’s accuracy improves, rising from $57.40\%$ to $84.63\%$, whereas competitors like FGSD see performance degrade from $58.00\%$ to $51.57\%$, indicating that prior methods struggle to capture global structure beyond local variations. This structural expressiveness is matched by superior computational efficiency. On the massive REDDIT-L dataset containing graphs with over one million nodes, NetLSD computes spectral signatures in approximately 16 minutes using an eigenvalue approximation strategy. In contrast, both NetSimile \cite{10.1145/2492517.2492582} and FGSD \cite{NIPS2017_d2ddea18} fail to complete processing within a 24-hour cutoff, establishing NetLSD as a uniquely viable solution for comparing web-scale graphs where traditional kernel methods and statistical aggregations become computationally prohibitive.

However, NetLSD requires precise tuning. For instance, the wave kernel favors complete-graph normalization while the heat kernel requires empty-graph normalization \cite{Tsitsulin_2018}. The method also inherits spectral limitations like cospectrality and "abnormal sensitivity," where minor perturbations cause significant spectral shifts \cite{Tantardini2019ComparingMF}. Additionally, eigenvalue approximation faces diminishing returns—doubling steps from 200 to 400 yields negligible accuracy gains (rising from $0.980$ to $0.985$)  \cite{szakacs2023whole}, and newer architectures like FeatherGraph demonstrate superior runtime and performance \cite{rozemberczki2020characteristicfunctionsgraphsbirds}. Thus, while NetLSD resolves the scalability bottlenecks of Graph Edit Distance \cite{RIESEN2009950} and FGSD \cite{NIPS2017_d2ddea18}, successful deployment necessitates careful calibration to mitigate these intrinsic constraints.

\section{General Notation}
We define a Graph as $G(V, E)$ Where $V = \{1, 2, ..., n\}$ represents the nodes and $E = \{ (u_i, v_i), ..., (u_j, v_j)\}$ represents the edges. Each graph can appear as an adjacency list where we map nodes with lists of other nodes or with an adjacency matrix $A \in \{0, 1\}^{n \times n}$ where $A_{ij} = 1: (u_i, u_j) \in E$. We also define a node labeling function $\lambda_i$ that maps nodes to a class $l$ and a graph labeling function $\mu_i$ that maps graphs to a class $c$. We will have two types of graphs in total, graphs that have node attributes, thus, for each node $u_i \in V \longrightarrow h_i \in R^d$ and graphs that don't have node attributes, thus, we have to learn from structure only. Our objective for graph classification tasks is to learn a function that produces optimal embeddings for each graph $f(G, \mu): R^{n \times n} \longrightarrow R^d$ and for node classification we have to learn a function $f$ that produces optimal embeddings for each node $f(G, \lambda): R^{n \times n} \longrightarrow R^{n \times d}$. For short, we define these embeddings as $\Phi$.

\section{Models}

\subsection{Graph Representation Learning Models}

\subsubsection*{\textbf{Graph2Vec}}

Graph2Vec \cite{narayanan2017graph2veclearningdistributedrepresentations} produces embeddings $\Phi \in \mathbb{R}^{G \times d}$ for a dataset of graphs $\mathcal{G} = \{G_1, G_2, ..., G_n\}$.
Rooted subgraph extraction follows the Weisfeiler--Lehman procedure \cite{shervashidze2011weisfeiler}. For a root node $n$ and height $h$, the procedure generates identifier $sg_n^{(h)}$ through iterative relabeling based on sorted multisets of neighbor labels, where height corresponds to the maximum distance from the root node. The training objective for each subgraph $sg_n^{(h)}$ extracted from graph $G_i$ is:
\begin{equation}
J(\Phi) = -\log \Pr(sg_n^{(h)} | \Phi(G_i))
\end{equation}
where $\Phi(G_i) \in \mathbb{R}^{\delta}$ represents the graph embedding vector. 

Computing $\Pr(sg_n^{(h)} | \Phi(G_i))$ with softmax normalization over the full subgraph vocabulary requires $O(|V_{sg}|)$ complexity. Graph2Vec instead applies negative sampling from the doc2vec PV-DBOW framework, approximating the objective by sampling $k$ negative subgraphs not present in the target graph. This reduces the per-update cost to $O(k)$ where $k \ll |V_{sg}|$. The gradient update follows:
\begin{equation}
\Phi \leftarrow \Phi - \alpha \frac{\partial J}{\partial \Phi}
\end{equation}
where $\alpha$ denotes the learning rate. Training iterates over all graphs for $e$ epochs, shuffling graphs at each epoch. For each graph, rooted subgraphs up to height $h$ are extracted around every node before applying stochastic gradient descent updates.

\subsubsection*{\textbf{DeepWalk}}

DeepWalk \cite{Perozzi_2014} generates $d$-dimensional node embeddings $\Phi \in \mathbb{R}^{|V| \times d}$ for graph $G = (V, E)$. The algorithm samples $\gamma$ random walks of length $t$ from each vertex $v_i \in V$, with each walk $W_{v_i}$ uniformly sampling neighbors at each step.

The skip-gram training objective \cite{mikolov2013efficientestimationwordrepresentations} processes each vertex $v_j$ in walk $W_{v_i}$ by iterating over a context window of size $w$. For each context vertex $u_k \in W_{v_i}[j-w : j+w]$, the algorithm minimizes:
\begin{equation}
J(\Phi) = -\log \Pr(u_k | \Phi(v_j))
\end{equation}

Direct computation of $\Pr(u_k | \Phi(v_j))$ via softmax over all vertices requires $O(|V|)$ operations per sample. Hierarchical softmax reduces this to $O(\log |V|)$ by arranging vertices as leaves of a binary tree. For vertex $u_k$ with tree path $(b_0, b_1, ..., b_{\lceil \log |V| \rceil})$ from root to leaf:
\begin{equation}
\Pr(u_k | \Phi(v_j)) = \prod_{l=1}^{\lceil \log |V| \rceil} \Pr(b_l | \Phi(v_j))
\end{equation}
where each factor represents a binary classifier at tree node $b_l$. Huffman encoding assigns shorter paths to frequently sampled vertices, further improving efficiency.

The algorithm executes $\gamma$ passes over vertices. The learning rate $\alpha$ begins at $2.5\%$ and decreases linearly with the number of vertices processed \cite{Perozzi_2014}. The power-law distribution of vertex frequencies in random walks creates sparse gradient updates, enabling lock-free asynchronous parallel training across multiple workers.

For graph-level tasks, node embeddings aggregate via mean pooling $\Phi(G) = \frac{1}{|V|}\sum_{v \in V} \Phi(v)$ or max pooling, though such simple aggregation cannot recover global structural properties effectively \cite{narayanan2017graph2veclearningdistributedrepresentations}.

\subsubsection*{\textbf{NetLSD}}

NetLSD \cite{Tsitsulin_2018} constructs a permutation- and size-invariant graph representation by modeling global structural properties through spectral physics. Given a graph $G$ with normalized Laplacian $L = I - D^{-\frac{1}{2}}AD^{-\frac{1}{2}}$ and eigenvalues $0 \leq \lambda_1 \leq \dots \leq \lambda_n \leq 2$, the method extracts a signature based on the solution to either the heat or wave equation. 

For heat diffusion, governed by $\frac{\partial u_t}{\partial t} = -Lu_t$, the solution is the heat kernel $H_t = e^{-tL}$. This acts as a low-pass filter, emphasizing global community structure while smoothing out local noise. The heat trace is defined as:\begin{equation}h_t = \text{tr}(H_t) = \sum_{j=1}^n e^{-t\lambda_j}\end{equation}

Alternatively, to capture resonance patterns and high-frequency details that heat diffusion dampens, NetLSD employs the wave equation $\frac{\partial^2 u_t}{\partial t^2} = -Lu_t$. This describes a wave propagating through the graph medium, with the solution given by the complex-valued wave kernel $W_t = e^{-itL}$. Unlike the heat kernel, the wave kernel does not decay high eigenvalues, allowing it to "hear" finer local shapes. The wave trace at time $t \in [0, 2\pi)$ is:\begin{equation}w_t = \text{tr}(W_t) = \sum_{j=1}^n e^{-it\lambda_j}\end{equation}

Computing the full spectrum requires $O(n^3)$ time, which is prohibitive for large graphs. To address this, the authors propose two approximation strategies. For very large graphs or small time scales $t$, the method utilizes a Taylor expansion of the matrix exponential, enabling a linear-time approximation using the first two terms:
\begin{equation}
h_t \approx n - t \text{tr}(L) + \frac{t^2}{2} \text{tr}(L^2)
\end{equation}
Since $\text{tr}(L)=n$ and $\text{tr}(L^2) = \sum_{ij} L_{ij}^2$, this is computable in $O(m)$ time. For manageable graph sizes, the method adopts a more accurate strategy based on Weyl’s law \cite{Weyl1911} to capture medium-scale properties. Instead of the full spectrum, it computes only $k$ eigenvalues at both ends of the spectrum (smallest and largest) using the block Krylov-Schur algorithm \cite{10.1145/1089014.1089019} and approximates the interloping eigenvalues via linear interpolation.

\subsection{Graph Neural Network Models}

\subsubsection*{\textbf{GCN}}

\subsubsection*{\textbf{GAT}}
Graph Attention Network(GAT) \cite{veličković2018graphattentionnetworks} was the first model that introduced masked self-attention to GNN models, enabling each node to assign different importances to other nodes of the same neighborhood. This is also beneficial for interpretability. The model is applied to graphs that contain node attributes $h = \{ h_1, h_2, ..., h_n\}$, $h_i \in R^{d}$, each layer produce new embeddings $h' = \{ h_1', h_2', ..., h_n'\}$, $h_i' \in R^{d'}$. Self-attention is applied to all the nodes with a shared attention mechanism $\alpha: R^d \times R^d \longrightarrow R$ that computes attention coefficients \[e_{ij} = \alpha(Wh_i, Wh_j)\] that indicates importance of node's j features to node i. $W \in R ^{d' \times d}$ is a weight matrix. Authors used a single-layer feedforward neural network as the attention mechanism that computes $\alpha_{ij}$. Also, they found multi-head attention beneficial, thus, computing new embeddings $h_i'$ requires concatenating or averaging all the aggregated features from each head \[h_{ij}' = \oplus\sigma(\sum_{j \in N_i}a_{ij}^kW^kh_j)\]
Where $\sigma$ is the simgoid function and $k$ indicates the $k$-th attention mechanism. In the last layer, concatenation is not possible, using averaging instead.

The model is computationally efficient as it needs $O(|V|dd' + |E|d')$ and individual head's computations can be parallelized.
\subsubsection*{\textbf{GIN}}

\subsubsection*{\textbf{PNA}}

\section{Datasets \& Evaluation}
We performed training and evaluation on multiple graph datasets from TUDataset \cite{morris2020tudatasetcollectionbenchmarkdatasets} and a node regression task with data from NiChart's ISTAGING project(paper still under review at Nature Neuroscience).

\subsection{TUDataset}

We selected 4 datasets from TUDataset list in total: ENZYMES, IMDB-MULTI, MUTAG, PROTEINS and REDDIT-MULTI-5K. Out of them, ENZYMES and PROTEINS have node attributes, thus, can be used for GNN training. For every training iteration we used $75\%$ of the data for training and $25\%$ for testing. We present testing results over 3 training iterations and the best checkpoint was selected using F1 score. All the models were trained for 1000 total epochs with a patience of 100 epochs to ensure convergence, we chose Adadelta \cite{zeiler2012adadeltaadaptivelearningrate} as the optimizer with an initial learning rate of 0.1 and a batch size of 2 graphs.


\begin{table}[htbp]
\caption{Datasets used from TUDataset}
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|}
\hline
\textbf{Dataset} & \textbf{\textit{Graphs}}& \textbf{\textit{Classes}} & \textbf{\textit{Avg. Nodes}} & \textbf{\textit{Avg. Edges}} \\
\hline
ENZYMES & 600 & 6 & 32.63 & 62.14\\
\hline
MUTAG & 188 & 2 & 30.32 & 30.77\\
\hline
IMDB-MULTI & 1500 & 3 & 13.00 & 65.94\\
\hline
REDDIT-MULTI-5K & 4999 & 5 & 508.52 & 594.87\\
\hline
PROTEINS & 1113 & 2 & 39.06 & 72.82\\
\hline
\end{tabular}
\label{tab2}
\end{center}
\end{table}

\subsubsection*{\textbf{ENZYMES}}
The ENZYMES dataset contains 600 proteins from each of the 6 enzyme commission top-level enzyme classes and the goal was to correctly predict enzyme class membership for these proteins. So each protein is represented with a graph and we have a graph classification task.
For the GCN model we used 4 layers all with 256 hidden channels and a final layer of 128 output channels, dropout at 0.5. For the GAT and GIN model we used 2 layers all with 64 hidden channels and a final layer of 128 output channels, dropout at 0.5. For the PNA model we used 4 layers all with 64 hidden channels and a final layer of 128 output channels, dropout at 0.5. We should note that when we used 1) a smaller dropout value or no dropout at all, 2) more layers or 3) more hidden channels, overfitting increased. Testing results presented on Table II. After 3 runs, GAT had the best results by far, with $3\%$ higher Accuracy and F1 score than PNA, which came second. Not only GAT produce better results, but it has a much faster inference time than PNA with $1.44$ms on average, in contrast with $2ms$ on average for PNA.

\begin{table}[htbp]
\caption{Testing results for ENZYMES}
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{Model} & \textbf{\textit{ACC}}& \textbf{\textit{AUC}} & \textbf{\textit{F1}} \\
\hline
GCN & $0.61 \pm 0.02$ & $0.84 \pm 0.02$ & $0.61 \pm 0.02$ \\
\hline
GAT & \bm{$0.66 \pm 0.01$} & \bm{$0.85 \pm 0.004$} & \bm{$0.67 \pm 0.01$} \\
\hline
PNA & $0.63 \pm 0.05$ & $0.85 \pm 0.03$ & $0.63 \pm 0.05$ \\
\hline
GIN & $0.61 \pm 0.02 $ & $0.84 \pm 0.02$ & $0.61 \pm 0.02$ \\
\hline
\end{tabular}
\label{tab2}
\end{center}
\end{table}

\subsubsection*{\textbf{PROTEINS}}
The PROTEINS dataset is a medium sized molecular property prediction dataset. This dataset is used for molecular property prediction aiming to predict whether molecules are enzymes or not, thus, a binary classification task. We used the full version of the dataset, resulting in node attributes with a dimensionality of 29, which is the biggest out of all the datasets we are performing analysis on. We used the exact same model architectures as with the ENZYMES dataset, epochs, patience and batch size except for the PNA model, where we used 2 total layers instead of 4. We observed faster convergence as training results achieved good scores very early, this is logical as we have more features to train on and a much larger dataset than ENZYMES. After 3 runs, PNA had the best results with $3\%$ higher accuracy than GAT and $2\%$  higher F1 score than GIN and PNA. Because we only used 2 layers for the PNA model, the average inference time was only $0.7$ms in contrast with $1.9$ms for GAT. GIN had the best inference time with $0.3$ms on average.

\begin{table}[htbp]
\caption{Testing results for PROTEINS}
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{Model} & \textbf{\textit{ACC}}& \textbf{\textit{AUC}} & \textbf{\textit{F1}} \\
\hline
GCN & $0.72 \pm 0.002 $ & $0.76 \pm 0.007$ & $0.67 \pm 0.004$ \\
\hline
GAT & $0.76 \pm 0.01$ & $0.75 \pm 0.004$ & $0.70 \pm 0.01$ \\
\hline
PNA & \bm{$0.79 \pm 0.003$} & \bm{$0.85 \pm 0.003$} & \bm{$0.72 \pm 0.003$} \\
\hline
GIN & $0.75 \pm 0.008 $ & $0.80 \pm 0.01$ & $0.72 \pm 0.006$ \\
\hline
\end{tabular}
\label{tab2}
\end{center}
\end{table}

For Graph2Vec and DeepWalk, we used 128-dimensional embeddings with two downstream classifiers: SVM and MLP. Hyperparameters were optimized using Optuna with 200 trials. Testing results are presented in Table~\ref{tab:proteins_graph_results}.

\begin{table}[htbp]
\caption{Testing results for PROTEINS with Graph2Vec and DeepWalk}
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{Model} & \textbf{\textit{ACC}}& \textbf{\textit{AUC}} & \textbf{\textit{F1}} \\
\hline
DeepWalk + SVM & $0.70 \pm 0.01$ & $0.75 \pm 0.01$ & $0.65 \pm 0.01$ \\
\hline
DeepWalk + MLP & \bm{$0.72 \pm 0.01$} & \bm{$0.76 \pm 0.00$} & $0.65 \pm 0.02$ \\
\hline
Graph2Vec + SVM & $0.68 \pm 0.01$ & $0.72 \pm 0.00$ & $0.63 \pm 0.01$ \\
\hline
Graph2Vec + MLP & $0.68 \pm 0.01$ & $0.72 \pm 0.00$ & $0.63 \pm 0.02$ \\
\hline
\end{tabular}
\label{tab:proteins_graph_results}
\end{center}
\end{table}

DeepWalk with MLP classifier achieved the best performance among graph representation learning models with $72\%$ accuracy and 0.76 AUC, outperforming Graph2Vec by $4\%$ in accuracy. This performance gap suggests that for protein structure classification, the local spatial and sequential patterns encoded through random walks provide more discriminative power than global subgraph distributions. The MLP classifier showed a $2\%$ improvement over SVM for DeepWalk, indicating the learned embeddings benefit from non-linear decision boundaries. Both Graph2Vec and DeepWalk achieved lower performance compared to supervised GNN approaches on this dataset, which is expected given they operate purely on graph structure without node attributes. DeepWalk's average inference time was 11.4 seconds per graph on the PROTEINS dataset.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth]{images/TSNE_PROTEINS.png}
    \caption{Latent embeddings with TSNE for the PROTEINS dataset with the best PNA model}
    \label{fig:TSNE_PROTEINS}
\end{figure}


\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth]{images/TSNE_ENZYMES.png}
    \caption{Latent embeddings with TSNE for the ENZYMES dataset with the best GAT model}
    \label{fig:TSNE_ENZYMES}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth]{images/TSNE_PROTEINS_deepwalk.png}
    \caption{Latent embeddings with TSNE for the PROTEINS dataset with the best DeepWalk model}
    \label{fig:TSNE_PROTEINS_deepwalk}
\end{figure}

\subsubsection*{\textbf{IMDB-MULTI}}
The IMDB-MULTI dataset contains 1,500 movie collaboration graphs from three genres, where each graph represents ego-networks of actors and actresses who appeared in movies from the same genre. This presents a graph classification task  with three classes. Graph2Vec and DeepWalk used 128-dimensional embeddings with two downstream classifiers: SVM and MLP. To justify this choice, we evaluated DeepWalk on MUTAG with varying embedding dimensions (64, 128, 256, 512) and found that 128 dimensions provided the best balance between accuracy (87.2\%) and computational efficiency, with higher dimensions yielding diminishing returns or even decreased performance. For Graph2Vec, WL iterations were selected from $\{2, 3, 4\}$, while DeepWalk tested walk numbers in $\{2, 5, 7\}$, walk lengths in $\{5, 7, 10\}$, and window sizes in $\{3, 5, 10\}$. Learning rates were optimized between $10^{-4}$ and $10^{-1}$ on a logarithmic scale using Optuna with 200 trials. Testing results are presented in Table~\ref{tab:imdb_results}.

\begin{table}[htbp]
\caption{Testing results for IMDB-MULTI}
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{Model} & \textbf{\textit{ACC}}& \textbf{\textit{AUC}} & \textbf{\textit{F1}} \\
\hline
DeepWalk + SVM & $0.44 \pm 0.00$ & $0.61 \pm 0.01$ & $0.43 \pm 0.01$ \\
\hline
DeepWalk + MLP & $0.44 \pm 0.03$ & $0.59 \pm 0.02$ & $0.43 \pm 0.03$ \\
\hline
Graph2Vec + SVM & \bm{$0.49 \pm 0.01$} & \bm{$0.66 \pm 0.01$} & \bm{$0.48 \pm 0.01$} \\
\hline
Graph2Vec + MLP & \bm{$0.49 \pm 0.01$} & \bm{$0.66 \pm 0.01$} & \bm{$0.48 \pm 0.01$} \\
\hline
\end{tabular}
\label{tab:imdb_results}
\end{center}
\end{table}

Graph2Vec substantially outperformed DeepWalk by $5\%$ in accuracy and F1 score. Graph2Vec's data-driven subgraph embedding approach proved more effective at capturing the structural patterns distinguishing different movie genres. Both SVM and MLP classifiers achieved similar performance with Graph2Vec embeddings, suggesting the learned representations are robust across different downstream classifiers. DeepWalk's uniform random walk strategy appears insufficient for this task, likely due to the relatively small graph sizes (average 13 nodes) where global structural properties matter more than local neighborhood patterns. Graph2Vec's average inference time was 638 ms per graph on IMDB-MULTI.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth]{images/TSNE_IMDB-MULTI_graph2vec.png}
    \caption{Latent embeddings with TSNE for the IMDB-MULTI dataset with the best Graph2Vec model}
    \label{fig:TSNE_IMDB_graph2vec}
\end{figure}

\subsubsection*{\textbf{MUTAG}}
The MUTAG dataset comprises 188 chemical compounds labeled by their mutagenic effect on a specific bacterium, representing a binary classification task. MUTAG graphs are relatively small (average 30.32 nodes, 30.77 edges) but structurally complex. We used the same experimental configuration as IMDB-MULTI with 128-dimensional embeddings and 200 Optuna trials. Testing results are presented in Table~\ref{tab:mutag_results}.

\begin{table}[htbp]
\caption{Testing results for MUTAG}
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{Model} & \textbf{\textit{ACC}}& \textbf{\textit{AUC}} & \textbf{\textit{F1}} \\
\hline
DeepWalk + SVM & \bm{$0.87 \pm 0.01$} & \bm{$0.86 \pm 0.01$} & \bm{$0.90 \pm 0.01$} \\
\hline
DeepWalk + MLP & \bm{$0.87 \pm 0.02$} & \bm{$0.86 \pm 0.01$} & \bm{$0.90 \pm 0.01$} \\
\hline
Graph2Vec + SVM & $0.85 \pm 0.02$ & $0.84 \pm 0.00$ & $0.89 \pm 0.01$ \\
\hline
Graph2Vec + MLP & $0.84 \pm 0.03$ & $0.85 \pm 0.03$ & $0.89 \pm 0.01$ \\
\hline
\end{tabular}
\label{tab:mutag_results}
\end{center}
\end{table}

In contrast to IMDB-MULTI, DeepWalk achieved superior performance on MUTAG, outperforming Graph2Vec by $2$-$3\%$ in accuracy. This reversal can be attributed to MUTAG's molecular structure where local neighborhood patterns captured by random walks are highly discriminative for mutagenicity. The consistent node degree distributions and regular substructures in chemical graphs align well with DeepWalk's uniform exploration strategy. Both methods achieved F1 scores around 0.89-0.90, demonstrating that our hyperparameter optimization was effective. The choice between SVM and MLP had minimal impact for both models. DeepWalk's average inference time was 1.08 seconds per graph on MUTAG.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth]{images/TSNE_MUTAG_deepwalk.png}
    \caption{Latent embeddings with TSNE for the MUTAG dataset with the best DeepWalk model}
    \label{fig:TSNE_MUTAG_deepwalk}
\end{figure}

The comparative analysis across all three datasets reveals that the relative performance of Graph2Vec and DeepWalk depends strongly on dataset characteristics and structural properties. Graph2Vec excels on social network datasets such as IMDB-MULTI, where global structural patterns and subgraph distributions effectively distinguish between different graph classes. In contrast, DeepWalk achieves superior performance on molecular and biological graphs (MUTAG, PROTEINS), where local neighborhood patterns captured through random walks prove more discriminative for classification tasks. The choice of downstream classifier shows differential effects: while Graph2Vec performance remains consistent across SVM and MLP classifiers, DeepWalk benefits from non-linear decision boundaries provided by MLP on certain datasets, particularly for protein structure classification. Unsupervised k-means clustering analysis reveals varying degrees of natural grouping in the learned embeddings. IMDB-MULTI shows minimal clustering structure with an ARI score of 0.006, suggesting that social network embeddings require supervised signals for effective separation. However, both molecular datasets demonstrate moderate unsupervised clustering quality, with MUTAG achieving an ARI of 0.268 and PROTEINS reaching 0.183. These results indicate that graph embeddings from molecular and biological domains capture inherent structural similarities that align with class boundaries even without explicit label information.

\subsubsection*{\textbf{Stability Analysis}}

To evaluate the robustness of learned embeddings to graph perturbations, we conducted stability analysis on DeepWalk by introducing random structural changes to the graphs. For MUTAG, we tested edge removal and addition at three perturbation levels (15\%, 20\%, 25\%), while for PROTEINS we evaluated the effect of shuffling node attributes. The results are presented in Table~\ref{tab:stability_results}.

\begin{table}[htbp]
\caption{Stability analysis results for DeepWalk under various graph perturbations}
\begin{center}
\begin{tabular}{|c|c|c|c|c|}
\hline
\textbf{Dataset} & \textbf{Perturbation} & \textbf{\textit{ACC}} & \textbf{\textit{AUC}} & \textbf{\textit{F1}} \\
\hline
MUTAG & Original & $0.87$ & $0.86$ & $0.90$ \\
\hline
MUTAG & Remove 15\% edges & $0.87$ & $0.89$ & $0.91$ \\
\hline
MUTAG & Remove 20\% edges & $0.85$ & $0.86$ & $0.89$ \\
\hline
MUTAG & Remove 25\% edges & $0.81$ & $0.86$ & $0.86$ \\
\hline
MUTAG & Add 15\% edges & $0.83$ & $0.84$ & $0.88$ \\
\hline
MUTAG & Add 20\% edges & $0.85$ & $0.84$ & $0.89$ \\
\hline
MUTAG & Add 25\% edges & $0.81$ & $0.86$ & $0.86$ \\
\hline
\hline
PROTEINS & Original & $0.72$ & $0.76$ & $0.65$ \\
\hline
PROTEINS & Shuffle attributes & $0.71$ & $0.74$ & $0.66$ \\
\hline
\end{tabular}
\label{tab:stability_results}
\end{center}
\end{table}

DeepWalk demonstrates remarkable stability on MUTAG under moderate perturbations, maintaining accuracy within 2\% for edge removal up to 15\% and showing minimal degradation at 20\% removal. However, at 25\% perturbation, both edge removal and addition cause a more substantial accuracy drop of approximately 6\%, indicating the threshold beyond which structural changes significantly impact embedding quality. Edge addition generally proved more disruptive than removal at equivalent perturbation levels, likely because random edges introduce noise that disrupts the meaningful local neighborhood patterns that DeepWalk captures through random walks. On PROTEINS, shuffling node attributes resulted in minimal performance degradation (1\% accuracy drop), which is expected since DeepWalk operates purely on graph topology and does not utilize node features. Visual inspection of TSNE projections confirms these findings, with perturbed embeddings maintaining similar cluster structures to the original embeddings up to 20\% perturbation, beyond which notable distortions become apparent.

\section{Results \& Discussion}
\bibliographystyle{IEEEtran}
\bibliography{references}
\vspace{12pt}


\end{document}