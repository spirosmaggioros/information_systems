@misc{kipf2017semisupervisedclassificationgraphconvolutional,
      title={Semi-Supervised Classification with Graph Convolutional Networks}, 
      author={Thomas N. Kipf and Max Welling},
      year={2017},
      eprint={1609.02907},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1609.02907}, 
}

@misc{narayanan2017graph2veclearningdistributedrepresentations,
      title={graph2vec: Learning Distributed Representations of Graphs}, 
      author={Annamalai Narayanan and Mahinthan Chandramohan and Rajasekar Venkatesan and Lihui Chen and Yang Liu and Shantanu Jaiswal},
      year={2017},
      eprint={1707.05005},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/1707.05005}, 
}

@misc{xu2019powerfulgraphneuralnetworks,
      title={How Powerful are Graph Neural Networks?}, 
      author={Keyulu Xu and Weihua Hu and Jure Leskovec and Stefanie Jegelka},
      year={2019},
      eprint={1810.00826},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1810.00826}, 
}

@article{MicheliGNN,
  author={Micheli, Alessio},
  journal={IEEE Transactions on Neural Networks}, 
  title={Neural Network for Graphs: A Contextual Constructive Approach}, 
  year={2009},
  volume={20},
  number={3},
  pages={498-511},
  keywords={Neural networks;Machine learning;Recurrent neural networks;Context modeling;Neurons;Data structures;Kernel;Feedforward neural networks;Neurofeedback;State feedback;Cascade correlation;contextual transductions;graph patterns;learning in structured domains (SDs);neural networks for structured data;recursive neural networks},
  doi={10.1109/TNN.2008.2010350}
}

@article{scarselliGNN,
  author={Scarselli, Franco and Gori, Marco and Tsoi, Ah Chung and Hagenbuchner, Markus and Monfardini, Gabriele},
  journal={IEEE Transactions on Neural Networks}, 
  title={The Graph Neural Network Model}, 
  year={2009},
  volume={20},
  number={1},
  pages={61-80},
  keywords={Neural networks;Biological system modeling;Data engineering;Computer vision;Chemistry;Biology;Pattern recognition;Data mining;Supervised learning;Parameter estimation;Graphical domains;graph neural networks (GNNs);graph processing;recursive neural networks},
  doi={10.1109/TNN.2008.2005605}
}

@misc{veličković2018graphattentionnetworks,
      title={Graph Attention Networks}, 
      author={Petar Veličković and Guillem Cucurull and Arantxa Casanova and Adriana Romero and Pietro Liò and Yoshua Bengio},
      year={2018},
      eprint={1710.10903},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1710.10903}, 
}

@misc{opengraphbenchmarkdatasets,
      title={Open Graph Benchmark: Datasets for Machine Learning on Graphs}, 
      author={Weihua Hu and Matthias Fey and Marinka Zitnik and Yuxiao Dong and Hongyu Ren and Bowen Liu and Michele Catasta and Jure Leskovec},
      year={2021},
      eprint={2005.00687},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2005.00687}, 
}

@misc{luo2025classicgnnsstrongbaselines,
      title={Can Classic GNNs Be Strong Baselines for Graph-level Tasks? Simple Architectures Meet Excellence}, 
      author={Yuankai Luo and Lei Shi and Xiao-Ming Wu},
      year={2025},
      eprint={2502.09263},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2502.09263}, 
}

@misc{dwivedi2023longrangegraphbenchmark,
      title={Long Range Graph Benchmark}, 
      author={Vijay Prakash Dwivedi and Ladislav Rampášek and Mikhail Galkin and Ali Parviz and Guy Wolf and Anh Tuan Luu and Dominique Beaini},
      year={2023},
      eprint={2206.08164},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2206.08164}, 
}

@misc{togninalli2019wassersteinweisfeilerlehmangraphkernels,
      title={Wasserstein Weisfeiler-Lehman Graph Kernels}, 
      author={Matteo Togninalli and Elisabetta Ghisu and Felipe Llinares-López and Bastian Rieck and Karsten Borgwardt},
      year={2019},
      eprint={1906.01277},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1906.01277}, 
}

@inproceedings{Perozzi_2014, series={KDD ’14},
   title={DeepWalk: online learning of social representations},
   url={http://dx.doi.org/10.1145/2623330.2623732},
   DOI={10.1145/2623330.2623732},
   booktitle={Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining},
   publisher={ACM},
   author={Perozzi, Bryan and Al-Rfou, Rami and Skiena, Steven},
   year={2014},
   month=aug, pages={701–710},
   collection={KDD ’14} }

@misc{grover2016node2vecscalablefeaturelearning,
      title={node2vec: Scalable Feature Learning for Networks}, 
      author={Aditya Grover and Jure Leskovec},
      year={2016},
      eprint={1607.00653},
      archivePrefix={arXiv},
      primaryClass={cs.SI},
      url={https://arxiv.org/abs/1607.00653}, 
}

@misc{le2014distributedrepresentationssentencesdocuments,
      title={Distributed Representations of Sentences and Documents}, 
      author={Quoc V. Le and Tomas Mikolov},
      year={2014},
      eprint={1405.4053},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1405.4053}, 
}

@misc{mikolov2013distributedrepresentationswordsphrases,
      title={Distributed Representations of Words and Phrases and their Compositionality}, 
      author={Tomas Mikolov and Ilya Sutskever and Kai Chen and Greg Corrado and Jeffrey Dean},
      year={2013},
      eprint={1310.4546},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1310.4546}, 
}

@misc{mikolov2013efficientestimationwordrepresentations,
      title={Efficient Estimation of Word Representations in Vector Space}, 
      author={Tomas Mikolov and Kai Chen and Greg Corrado and Jeffrey Dean},
      year={2013},
      eprint={1301.3781},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1301.3781}, 
}

@misc{adhikari2017distributedrepresentationsubgraphs,
      title={Distributed Representation of Subgraphs}, 
      author={Bijaya Adhikari and Yao Zhang and Naren Ramakrishnan and B. Aditya Prakash},
      year={2017},
      eprint={1702.06921},
      archivePrefix={arXiv},
      primaryClass={cs.SI},
      url={https://arxiv.org/abs/1702.06921}, 
}

@inproceedings{Tsitsulin_2018, series={KDD ’18},
   title={NetLSD: Hearing the Shape of a Graph},
   url={http://dx.doi.org/10.1145/3219819.3219991},
   DOI={10.1145/3219819.3219991},
   booktitle={Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
   publisher={ACM},
   author={Tsitsulin, Anton and Mottin, Davide and Karras, Panagiotis and Bronstein, Alexander and Müller, Emmanuel},
   year={2018},
   month=jul, pages={2347–2356},
   collection={KDD ’18} }

@article{shervashidze2011weisfeiler,
  title   = {Weisfeiler-Lehman Graph Kernels},
  author  = {Shervashidze, Nino and Schweitzer, Pascal and van Leeuwen, Erik Jan and Mehlhorn, Kurt and Borgwardt, Karsten},
  journal = {Journal of Machine Learning Research},
  volume  = {12},
  pages   = {2539--2561},
  year    = {2011}
}

@inproceedings{yanardag2015deepgraphkernels,
  title        = {Deep Graph Kernels},
  author       = {Yanardag, Pinar and Vishwanathan, S. V. N.},
  booktitle    = {Proceedings of the 21st ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  year         = {2015},
  organization = {ACM}
}

@misc{brody2022attentivegraphattentionnetworks,
      title={How Attentive are Graph Attention Networks?}, 
      author={Shaked Brody and Uri Alon and Eran Yahav},
      year={2022},
      eprint={2105.14491},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2105.14491}, 
}

@misc{corso2020principalneighbourhoodaggregationgraph,
      title={Principal Neighbourhood Aggregation for Graph Nets}, 
      author={Gabriele Corso and Luca Cavalleri and Dominique Beaini and Pietro Liò and Petar Veličković},
      year={2020},
      eprint={2004.05718},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2004.05718}, 
}

@misc{chien2022nodefeatureextractionselfsupervised,
      title={Node Feature Extraction by Self-Supervised Multi-scale Neighborhood Prediction}, 
      author={Eli Chien and Wei-Cheng Chang and Cho-Jui Hsieh and Hsiang-Fu Yu and Jiong Zhang and Olgica Milenkovic and Inderjit S Dhillon},
      year={2022},
      eprint={2111.00064},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2111.00064}, 
}

@misc{veličković2018deepgraphinfomax,
      title={Deep Graph Infomax}, 
      author={Petar Veličković and William Fedus and William L. Hamilton and Pietro Liò and Yoshua Bengio and R Devon Hjelm},
      year={2018},
      eprint={1809.10341},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1809.10341}, 
}

@misc{morris2020tudatasetcollectionbenchmarkdatasets,
      title={TUDataset: A collection of benchmark datasets for learning with graphs}, 
      author={Christopher Morris and Nils M. Kriege and Franka Bause and Kristian Kersting and Petra Mutzel and Marion Neumann},
      year={2020},
      eprint={2007.08663},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2007.08663}, 
}

@misc{zeiler2012adadeltaadaptivelearningrate,
      title={ADADELTA: An Adaptive Learning Rate Method}, 
      author={Matthew D. Zeiler},
      year={2012},
      eprint={1212.5701},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1212.5701}, 
}

@article{RIESEN2009950,
title = {Approximate graph edit distance computation by means of bipartite graph matching},
journal = {Image and Vision Computing},
volume = {27},
number = {7},
pages = {950-959},
year = {2009},
note = {7th IAPR-TC15 Workshop on Graph-based Representations (GbR 2007)},
issn = {0262-8856},
doi = {https://doi.org/10.1016/j.imavis.2008.04.004},
url = {https://www.sciencedirect.com/science/article/pii/S026288560800084X},
author = {Kaspar Riesen and Horst Bunke},
keywords = {Graph based representation, Graph edit distance, Bipartite graph matching},
abstract = {In recent years, the use of graph based object representation has gained popularity. Simultaneously, graph edit distance emerged as a powerful and flexible graph matching paradigm that can be used to address different tasks in pattern recognition, machine learning, and data mining. The key advantages of graph edit distance are its high degree of flexibility, which makes it applicable to any type of graph, and the fact that one can integrate domain specific knowledge about object similarity by means of specific edit cost functions. Its computational complexity, however, is exponential in the number of nodes of the involved graphs. Consequently, exact graph edit distance is feasible for graphs of rather small size only. In the present paper we introduce a novel algorithm which allows us to approximately, or suboptimally, compute edit distance in a substantially faster way. The proposed algorithm considers only local, rather than global, edge structure during the optimization process. In experiments on different datasets we demonstrate a substantial speed-up of our proposed method over two reference systems. Moreover, it is emprically verified that the accuracy of the suboptimal distance remains sufficiently accurate for various pattern recognition applications.}
}

@inproceedings{10.5555/646337.688400,
author = {Lin, Chih-Long},
title = {Hardness of Approximating Graph Transformation Problem},
year = {1994},
isbn = {3540583254},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
booktitle = {Proceedings of the 5th International Symposium on Algorithms and Computation},
pages = {74–82},
numpages = {9},
series = {ISAAC '94}
}

@inproceedings{10.1109/ICDM.2005.132,
author = {Borgwardt, Karsten M. and Kriegel, Hans-Peter},
title = {Shortest-Path Kernels on Graphs},
year = {2005},
isbn = {0769522785},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICDM.2005.132},
doi = {10.1109/ICDM.2005.132},
abstract = {Data mining algorithms are facing the challenge to deal with an increasing number of complex objects. For graph data, a whole toolbox of data mining algorithms becomes available by defining a kernel function on instances of graphs. Graph kernels based on walks, subtrees and cycles in graphs have been proposed so far. As a general problem, these kernels are either computationally expensive or limited in their expressiveness. We try to overcome this problem by defining expressive graph kernels which are based on paths. As the computation of all paths and longest paths in a graph is NP-hard, we propose graph kernels based on shortest paths. These kernels are computable in polynomial time, retain expressivity and are still positive definite. In experiments on classification of graph models of proteins, our shortest-path kernels show significantly higher classificationaccuracy than walk-based kernels.},
booktitle = {Proceedings of the Fifth IEEE International Conference on Data Mining},
pages = {74–81},
numpages = {8},
series = {ICDM '05}
}

@InProceedings{10.1007/978-3-540-45167-9_11,
author="G{\"a}rtner, Thomas
and Flach, Peter
and Wrobel, Stefan",
editor="Sch{\"o}lkopf, Bernhard
and Warmuth, Manfred K.",
title="On Graph Kernels: Hardness Results and Efficient Alternatives",
booktitle="Learning Theory and Kernel Machines",
year="2003",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="129--143",
abstract="As most `real-world' data is structured, research in kernel methods has begun investigating kernels for various kinds of structured data. One of the most widely used tools for modeling structured data are graphs. An interesting and important challenge is thus to investigate kernels on instances that are represented by graphs. So far, only very specific graphs such as trees and strings have been considered.",
isbn="978-3-540-45167-9"
}

@misc{kondor2016multiscalelaplaciangraphkernel,
      title={The Multiscale Laplacian Graph Kernel}, 
      author={Risi Kondor and Horace Pan},
      year={2016},
      eprint={1603.06186},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1603.06186}, 
}

@article{Nikolentzos_Meladianos_Vazirgiannis_2017, title={Matching Node Embeddings for Graph Similarity}, volume={31}, url={https://ojs.aaai.org/index.php/AAAI/article/view/10839}, DOI={10.1609/aaai.v31i1.10839}, abstractNote={ &lt;p&gt; Graph kernels have emerged as a powerful tool for graph comparison. Most existing graph kernels focus on local properties of graphs and ignore global structure. In this paper, we compare graphs based on their global properties as these are captured by the eigenvectors of their adjacency matrices. We present two algorithms for both labeled and unlabeled graph comparison. These algorithms represent each graph as a set of vectors corresponding to the embeddings of its vertices. The similarity between two graphs is then determined using the Earth Mover’s Distance metric. These similarities do not yield a positive semidefinite matrix. To address for this, we employ an algorithm for SVM classification using indefinite kernels. We also present a graph kernel based on the Pyramid Match kernel that finds an approximate correspondence between the sets of vectors of the two graphs. We further improve the proposed kernel using the Weisfeiler-Lehman framework. We evaluate the proposed methods on several benchmark datasets for graph classification and compare their performance to state-of-the-art graph kernels. In most cases, the proposed algorithms outperform the competing methods, while their time complexity remains very attractive. &lt;/p&gt; }, number={1}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Nikolentzos, Giannis and Meladianos, Polykarpos and Vazirgiannis, Michalis}, year={2017}, month={Feb.}
}

@article{JMLR:v12:shervashidze11a,
  author  = {Nino Shervashidze and Pascal Schweitzer and Erik Jan van Leeuwen and Kurt Mehlhorn and Karsten M. Borgwardt},
  title   = {Weisfeiler-Lehman Graph Kernels},
  journal = {Journal of Machine Learning Research},
  year    = {2011},
  volume  = {12},
  number  = {77},
  pages   = {2539--2561},
  url     = {http://jmlr.org/papers/v12/shervashidze11a.html}
}

@inproceedings{10.1145/2783258.2783417,
author = {Yanardag, Pinar and Vishwanathan, S.V.N.},
title = {Deep Graph Kernels},
year = {2015},
isbn = {9781450336642},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2783258.2783417},
doi = {10.1145/2783258.2783417},
abstract = {In this paper, we present Deep Graph Kernels, a unified framework to learn latent representations of sub-structures for graphs, inspired by latest advancements in language modeling and deep learning. Our framework leverages the dependency information between sub-structures by learning their latent representations. We demonstrate instances of our framework on three popular graph kernels, namely Graphlet kernels, Weisfeiler-Lehman subtree kernels, and Shortest-Path graph kernels. Our experiments on several benchmark datasets show that Deep Graph Kernels achieve significant improvements in classification accuracy over state-of-the-art graph kernels.},
booktitle = {Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {1365–1374},
numpages = {10},
keywords = {bioinformatics, collaboration networks, deep learning, graph kernels, r-convolution kernels, social networks, string kernels, structured data},
location = {Sydney, NSW, Australia},
series = {KDD '15}
}

@inproceedings{NIPS2017_d2ddea18,
 author = {Verma, Saurabh and Zhang, Zhi-Li},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Hunt For The Unique, Stable, Sparse And Fast Feature Learning On Graphs},
 url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/d2ddea18f00665ce8623e36bd4e3c7c5-Paper.pdf},
 volume = {30},
 year = {2017}
}

@article{6d1fe8e1-9a0d-30f4-aeb4-baa6cceccb15,
 ISSN = {00029890, 19300972},
 URL = {http://www.jstor.org/stable/2313748},
 author = {Mark Kac},
 journal = {The American Mathematical Monthly},
 number = {4},
 pages = {1--23},
 publisher = {[Taylor & Francis, Ltd., Mathematical Association of America]},
 title = {Can One Hear the Shape of a Drum?},
 urldate = {2025-12-13},
 volume = {73},
 year = {1966}
}

@ARTICLE{5661779,
  author={Bronstein, Michael M. and Bronstein, Alexander M.},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Shape Recognition with Spectral Distances}, 
  year={2011},
  volume={33},
  number={5},
  pages={1065-1071},
  keywords={Shape;Kernel;Heating;Measurement;Eigenvalues and eigenfunctions;Transfer functions;Geometry;Diffusion distance;commute time;spectral distance;eigenmap;Laplace-Beltrami operator;heat kernel;distribution;global point signature;nonrigid shapes;similarity.},
  doi={10.1109/TPAMI.2010.210}
}

@inproceedings{10.5555/1735603.1735621,
author = {Sun, Jian and Ovsjanikov, Maks and Guibas, Leonidas},
title = {A concise and provably informative multi-scale signature based on heat diffusion},
year = {2009},
publisher = {Eurographics Association},
address = {Goslar, DEU},
abstract = {We propose a novel point signature based on the properties of the heat diffusion process on a shape. Our signature, called the Heat Kernel Signature (or HKS), is obtained by restricting the well-known heat kernel to the temporal domain. Remarkably we show that under certain mild assumptions, HKS captures all of the information contained in the heat kernel, and characterizes the shape up to isometry. This means that the restriction to the temporal domain, on the one hand, makes HKS much more concise and easily commensurable, while on the other hand, it preserves all of the information about the intrinsic geometry of the shape. In addition, HKS inherits many useful properties from the heat kernel, which means, in particular, that it is stable under perturbations of the shape. Our signature also provides a natural and efficiently computable multi-scale way to capture information about neighborhoods of a given point, which can be extremely useful in many applications. To demonstrate the practical relevance of our signature, we present several methods for non-rigid multi-scale matching based on the HKS and use it to detect repeated structure within the same shape and across a collection of shapes.},
booktitle = {Proceedings of the Symposium on Geometry Processing},
pages = {1383–1392},
numpages = {10},
location = {Berlin, Germany},
series = {SGP '09}
}

@INPROCEEDINGS{6130444,
  author={Aubry, Mathieu and Schlickewei, Ulrich and Cremers, Daniel},
  booktitle={2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops)}, 
  title={The wave kernel signature: A quantum mechanical approach to shape analysis}, 
  year={2011},
  volume={},
  number={},
  pages={1626-1633},
  keywords={Shape;Kernel;Heating;Eigenvalues and eigenfunctions;Particle measurements;Atmospheric measurements;Energy measurement},
  doi={10.1109/ICCVW.2011.6130444}
}

@InProceedings{10.1007/978-3-642-13672-6_40,
author="Akoglu, Leman
and McGlohon, Mary
and Faloutsos, Christos",
editor="Zaki, Mohammed J.
and Yu, Jeffrey Xu
and Ravindran, B.
and Pudi, Vikram",
title="oddball: Spotting Anomalies in Weighted Graphs",
booktitle="Advances in Knowledge Discovery and Data Mining",
year="2010",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="410--421",
abstract="Given a large, weighted graph, how can we find anomalies? Which rules should be violated, before we label a node as an anomaly? We propose the oddball algorithm, to find such nodes. The contributions are the following: (a) we discover several new rules (power laws) in density, weights, ranks and eigenvalues that seem to govern the so-called ``neighborhood sub-graphs'' and we show how to use these rules for anomaly detection; (b) we carefully choose features, and design oddball, so that it is scalable and it can work un-supervised (no user-defined constants) and (c) we report experiments on many real graphs with up to 1.6 million nodes, where oddball indeed spots unusual nodes that agree with intuition.",
isbn="978-3-642-13672-6"
}

@ARTICLE{868688,
  author={Jianbo Shi and Malik, J.},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Normalized cuts and image segmentation}, 
  year={2000},
  volume={22},
  number={8},
  pages={888-905},
  keywords={Image segmentation;Brightness;Clustering algorithms;Data mining;Eigenvalues and eigenfunctions;Bayesian methods;Coherence;Tree data structures;Filling;Partitioning algorithms},
  doi={10.1109/34.868688}
}

@inproceedings{10.1145/2492517.2492582,
author = {Berlingerio, Michele and Koutra, Danai and Eliassi-Rad, Tina and Faloutsos, Christos},
title = {Network similarity via multiple social theories},
year = {2013},
isbn = {9781450322409},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2492517.2492582},
doi = {10.1145/2492517.2492582},
abstract = {Given a set of k networks, possibly with different sizes and no overlaps in nodes or links, how can we quickly assess similarity between them? Analogously, are there a set of social theories which, when represented by a small number of descriptive, numerical features, effectively serve as a "signature" for the network? Having such signatures will enable a wealth of graph mining and social network analysis tasks, including clustering, outlier detection, visualization, etc. We propose a novel, effective, and scalable method, called NETSIMILE, for solving the above problem. Our approach has the following desirable properties: (a) It is supported by a set of social theories. (b) It gives similarity scores that are size-invariant. (c) It is scalable, being linear on the number of links for graph signature extraction. In extensive experiments on numerous synthetic and real networks from disparate domains, NETSIMILE outperforms baseline competitors. We also demonstrate how our approach enables several mining tasks such as clustering, visualization, discontinuity detection, network transfer learning, and re-identification across networks.},
booktitle = {Proceedings of the 2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
pages = {1439–1440},
numpages = {2},
location = {Niagara, Ontario, Canada},
series = {ASONAM '13}
}

@article{Tantardini2019ComparingMF,
  title={Comparing methods for comparing networks},
  author={Mattia Tantardini and Francesca Ieva and Lucia Tajoli and Carlo Piccardi},
  journal={Scientific Reports},
  year={2019},
  volume={9},
  url={https://api.semanticscholar.org/CorpusID:208278792}
}

@article{szakacs2023whole,
  title={Whole Graph Embedding Methods and Their Performances},
  author={Szak{\'a}cs, Lili Kata and Bencz{\'u}r, Andr{\'a}s and B{\'e}res, Ferenc},
  year={2023}
}

@misc{rozemberczki2020characteristicfunctionsgraphsbirds,
      title={Characteristic Functions on Graphs: Birds of a Feather, from Statistical Descriptors to Parametric Models}, 
      author={Benedek Rozemberczki and Rik Sarkar},
      year={2020},
      eprint={2005.07959},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2005.07959}, 
}

@article{Weyl1911,
author = {Weyl, H.},
journal = {Nachrichten von der Gesellschaft der Wissenschaften zu Göttingen, Mathematisch-Physikalische Klasse},
pages = {110-117},
title = {Ueber die asymptotische Verteilung der Eigenwerte},
url = {http://eudml.org/doc/58792},
volume = {1911},
year = {1911},
}

@article{10.1145/1089014.1089019,
author = {Hernandez, Vicente and Roman, Jose E. and Vidal, Vicente},
title = {SLEPc: A scalable and flexible toolkit for the solution of eigenvalue problems},
year = {2005},
issue_date = {September 2005},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {3},
issn = {0098-3500},
url = {https://doi.org/10.1145/1089014.1089019},
doi = {10.1145/1089014.1089019},
abstract = {The Scalable Library for Eigenvalue Problem Computations (SLEPc) is a software library for computing a few eigenvalues and associated eigenvectors of a large sparse matrix or matrix pencil. It has been developed on top of PETSc and enforces the same programming paradigm.The emphasis of the software is on methods and techniques appropriate for problems in which the associated matrices are sparse, for example, those arising after the discretization of partial differential equations. Therefore, most of the methods offered by the library are projection methods such as Arnoldi or Lanczos, or other methods with similar properties. SLEPc provides basic methods as well as more sophisticated algorithms. It also provides built-in support for spectral transformations such as the shift-and-invert technique. SLEPc is a general library in the sense that it covers standard and generalized eigenvalue problems, both Hermitian and non-Hermitian, with either real or complex arithmetic.SLEPc can be easily applied to real world problems. To illustrate this, several case studies arising from real applications are presented and solved with SLEPc with little programming effort. The addressed problems include a matrix-free standard problem, a complex generalized problem, and a singular value decomposition. The implemented codes exhibit good properties regarding flexibility as well as parallel performance.},
journal = {ACM Trans. Math. Softw.},
month = sep,
pages = {351–362},
numpages = {12},
keywords = {Eigenvalue computation, singular values, spectral transform}
}